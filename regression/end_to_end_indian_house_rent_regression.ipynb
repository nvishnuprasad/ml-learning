{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e7eb491",
   "metadata": {},
   "source": [
    "\n",
    "# End-to-End Regression: Predicting House Rent in Indian Cities\n",
    "\n",
    "This notebook walks through a complete machine learning workflow using a real Indian rental housing dataset.\n",
    "\n",
    "**Goal:** Predict monthly rent using housing attributes.  \n",
    "**Focus:** Practical ML workflow, not mathematical depth.  \n",
    "**Style:** Clean steps, clear reasoning, reusable code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd71dd",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load the data\n",
    "\n",
    "We begin by loading the dataset and taking a first look at its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62922b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/indian_house_rent.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51d516",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Understand the data\n",
    "\n",
    "We inspect the schema, data types, and basic statistics.\n",
    "This helps identify missing values and feature types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ceae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009be949",
   "metadata": {},
   "source": [
    "\n",
    "We also inspect categorical distributions to understand location and furnishing patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"city\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"furnishing\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249223a",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Define the machine learning task\n",
    "\n",
    "- **Target:** `rent` (continuous value)\n",
    "- **Type:** Supervised regression problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(\"rent\", axis=1)\n",
    "y = df[\"rent\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e81d20",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Trainâ€“test split\n",
    "\n",
    "We separate data into training and test sets.\n",
    "The test set simulates unseen future data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c744071",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "We explore key relationships using simple visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_train, bins=50)\n",
    "plt.xlabel(\"Monthly Rent\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Rent Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e269370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(df[\"area\"], df[\"rent\"], alpha=0.3)\n",
    "plt.xlabel(\"Area (sqft)\")\n",
    "plt.ylabel(\"Rent\")\n",
    "plt.title(\"Area vs Rent\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1f99d",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Correlation analysis\n",
    "\n",
    "We check numeric correlations to build intuition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "df[numeric_cols + [\"rent\"]].corr()[\"rent\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1861781",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Feature selection\n",
    "\n",
    "We keep clean, interpretable features.\n",
    "Free-text columns are excluded for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c473434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_features = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "cat_features = [\"city\", \"furnishing\"]\n",
    "\n",
    "X_train = X_train[num_features + cat_features]\n",
    "X_test = X_test[num_features + cat_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94e57c",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Preprocessing pipelines\n",
    "\n",
    "We prepare numeric and categorical features separately.\n",
    "This prevents data leakage and keeps transformations reusable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_features),\n",
    "    (\"cat\", categorical_pipeline, cat_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0daebd6",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Model training\n",
    "\n",
    "We train three regression models using the same preprocessing pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    results[name] = {\"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff075c1",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Error analysis\n",
    "\n",
    "We inspect where predictions fail the most.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "errors = X_test.copy()\n",
    "errors[\"actual_rent\"] = y_test\n",
    "errors[\"predicted_rent\"] = preds\n",
    "errors[\"abs_error\"] = abs(errors[\"actual_rent\"] - errors[\"predicted_rent\"])\n",
    "\n",
    "errors.sort_values(\"abs_error\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b34595",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Wrap-up\n",
    "\n",
    "- We walked through an end-to-end regression workflow.\n",
    "- The same structure applies to many ML problems.\n",
    "- Classification follows a similar pipeline with different targets and metrics.\n",
    "\n",
    "**Next steps:**\n",
    "- Cross-validation\n",
    "- Better models (Random Forest, Gradient Boosting)\n",
    "- Feature engineering\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
