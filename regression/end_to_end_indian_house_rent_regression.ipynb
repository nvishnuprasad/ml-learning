{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7f5f41",
   "metadata": {},
   "source": [
    "# End-to-End Regression Project using Indian Rental Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec37a-0bcb-45f7-85b9-0eced4e3f00a",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Regression: Problem Overview\n",
    "\n",
    "### What is Regression?\n",
    "\n",
    "**Regression** is a machine learning task where we predict a **continuous numeric value** from input features.\n",
    "\n",
    "Common regression problems include:\n",
    "\n",
    "* ðŸ  House price / rental prediction\n",
    "* ðŸ’¼ Salary prediction\n",
    "* ðŸ“ˆ Sales or demand estimation\n",
    "* âš¡ Energy or cost estimation\n",
    "\n",
    "All of these involve predicting a **numeric value**, not a category.\n",
    "\n",
    "### Type of Learning: Supervised\n",
    "\n",
    "This is a **supervised learning** problem.\n",
    "\n",
    "* We are given **input features (X)**\n",
    "* We are given the **correct output (y)**\n",
    "* The model learns the relationship between them from **labeled training data**\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "* **Inputs:** house attributes (area, city, bedrooms, furnishing, etc.)\n",
    "* **Target:** monthly rent\n",
    "\n",
    "### Dataset Used\n",
    "\n",
    "* Based on a **MagicBricks rental listings dataset (India)** [Kaggle Dataset Link](https://www.kaggle.com/datasets/pranayjagtap06/indian-rental-housing-price-dataset)\n",
    "* Slightly **modified for teaching purposes**\n",
    "\n",
    "  * to demonstrate preprocessing\n",
    "  * to handle missing values\n",
    "  * to build clean end-to-end pipelines\n",
    "\n",
    "### What Weâ€™ll Do in This Notebook\n",
    "\n",
    "We will walk through a **complete regression workflow**:\n",
    "\n",
    "1. Understand and explore the data\n",
    "2. Prepare features and handle missing values\n",
    "3. Split data into train / validation / test\n",
    "4. Build and compare regression models\n",
    "5. Evaluate on unseen test data\n",
    "\n",
    "The goal is to understand **how regression is applied end to end in practice**, not just to train a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9bd11b-2feb-48b3-aeb3-c5f3d48f807d",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "* Detailed setup instructions are available in the **README** of the repository\n",
    "* **Download the dataset** and place it inside the `data/` folder\n",
    "* This project uses **uv** for environment and dependency management\n",
    "* Clone the repo and follow the README â€” all required libraries (pandas, scikit-learn, matplotlib, etc.) will be installed automatically\n",
    "Once setup is complete, youâ€™re ready to run this notebook end to end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db55dd6",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "We start by loading the CSV into a DataFrame.\n",
    "Then we preview a few rows to understand the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is the standard library for working with tables in Python.\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = r\"data\\cities_magicbricks_rental_prices.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b6d37-3ed1-4a9a-a52a-15cab06f24da",
   "metadata": {},
   "source": [
    "### Dataset Overview & Feature Description\n",
    "\n",
    "Each row in the dataset represents a **single rental property listing**.\n",
    "Below is a brief description of the available features:\n",
    "\n",
    "| Feature        | Description                                           |\n",
    "| -------------- | ----------------------------------------------------- |\n",
    "| **house_type** | Title or type of the property                         |\n",
    "| **locality**   | Locality or neighborhood of the property              |\n",
    "| **city**       | City where the property is located                    |\n",
    "| **area**       | Property area in square feet (sq ft)                  |\n",
    "| **beds**       | Number of bedrooms                                    |\n",
    "| **bathrooms**  | Number of bathrooms                                   |\n",
    "| **balconies**  | Number of balconies                                   |\n",
    "| **furnishing** | Furnishing status of the property                     |\n",
    "| **area_rate**  | Area rate in Indian Rupees (â‚¹) per sq ft              |\n",
    "| **rent**       | Monthly rent in Indian Rupees (â‚¹) *(target variable)* |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe21cc",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - `rent` is the target we want to predict. It is continuous â†’ **regression**.\n",
    "> - We have numeric features (`area`, `beds`, â€¦) and categorical features (`city`, `furnishing`, â€¦).\n",
    "> - `house_type` is free text. We will skip it in the first baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f54f0",
   "metadata": {},
   "source": [
    "## 2) Quick data checks\n",
    "\n",
    "We check size, data types, and missing values.\n",
    "This tells us what preprocessing we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick dataset size summary (readable format)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "rows, cols = df.shape\n",
    "display(Markdown(f\"**Dataset size:** `{rows:,}` rows Ã— `{cols:,}` columns\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5e0b4",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - More rows usually means more stable model estimates.\n",
    "> - A small dataset can make model comparisons noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebca1a-b782-4f2b-8446-3fc2d7211c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic schema overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6136fa-4f08-44d7-88a3-47946697237d",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Categorical columns typically show up as `object`.\n",
    "> - Numeric columns show up as `int64` or `float64`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ffe50-1cfa-4e03-a288-a31b34b555c2",
   "metadata": {},
   "source": [
    "### Inspecting for Missing Values\n",
    "\n",
    "You should see a **small amount of missing values**.\n",
    "We injected them on purpose so we can demonstrate missing-value handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rich schema summary (types + missingness)\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "schema = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [str(t) for t in df.dtypes],\n",
    "    \"missing\": df.isna().sum().values,\n",
    "    \"missing_%\": (df.isna().mean() * 100).round(2).values,\n",
    "})\n",
    "schema = schema.sort_values([\"missing\", \"column\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "display(\n",
    "    schema.style\n",
    "        .format({\"missing\": \"{:,}\", \"missing_%\": \"{:.2f}%\"})\n",
    "        .bar(subset=[\"missing_%\"], align=\"mid\")\n",
    "        .set_caption(\"Schema summary (sorted by missingness)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9fab4",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Missing values are scattered.\n",
    "> - This is common in real data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dab8c",
   "metadata": {},
   "source": [
    "## 3) Handling missing data\n",
    "\n",
    "Missing data is normal in real projects.\n",
    "\n",
    "Common strategies:\n",
    "1. **Drop** rows or columns (fast, but you may lose signal)  \n",
    "2. **Impute** (replace with best guess) missing values (simple and effective for baselines)  \n",
    "3. **Model-based imputation** (KNN, MICE, etc. â€” more complex)\n",
    "\n",
    "In this notebook:\n",
    "- For **numeric** columns, we will impute using the **mean**.\n",
    "- For **categorical** columns, we will impute using the **most frequent** category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness percentage (top)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False).reset_index()\n",
    "missing_pct.columns = [\"column\", \"missing_%\"]\n",
    "\n",
    "display(\n",
    "    missing_pct.head(12).style\n",
    "        .format({\"missing_%\": \"{:.2f}%\"})\n",
    "        .bar(subset=[\"missing_%\"], align=\"mid\")\n",
    "        .set_caption(\"Missingness percentage (top columns)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515f0ef",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - If missingness is very high in a column (say 40%+), consider dropping it or collecting better data.\n",
    "> - Here, missingness is intentionally small. This makes imputation a reasonable choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16073c9e",
   "metadata": {},
   "source": [
    "### 3.1 Simple imputation demo (before pipelines)\n",
    "\n",
    "We will demonstrate imputation on a small subset.\n",
    "Later, we will do this properly inside a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputer is scikit-learn's standard tool for filling missing values.\n",
    "from sklearn.impute import SimpleImputer\n",
    "from IPython.display import display\n",
    "\n",
    "numeric_cols = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "\n",
    "cat_cols = [\"city\", \"furnishing\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "df_num_demo = pd.DataFrame(num_imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
    "df_cat_demo = pd.DataFrame(cat_imputer.fit_transform(df[cat_cols]), columns=cat_cols)\n",
    "\n",
    "missing_before_after = pd.DataFrame(\n",
    "    {\n",
    "        \"before_imputation\": [int(df[numeric_cols].isna().sum().sum()), int(df[cat_cols].isna().sum().sum())],\n",
    "        \"after_imputation\":  [int(df_num_demo.isna().sum().sum()), int(df_cat_demo.isna().sum().sum())],\n",
    "    },\n",
    "    index=[\"numeric (total)\", \"categorical (total)\"]\n",
    ")\n",
    "display(missing_before_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e2cd9",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - After imputation, the demo subsets contain **no missing values**.\n",
    "> - This is exactly what we want before training most models.\n",
    "> - We will do the same thing again inside a pipeline (the safer approach).\n",
    ">   \n",
    ">  **Questions**\n",
    "> - What is the problem with the approach of missing values?\n",
    "> - What would you do if the target column has a missing value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c730c-99a9-40ff-a869-54b2206d909d",
   "metadata": {},
   "source": [
    "### Demo: Full rows before vs after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9508c2-430f-4f8f-9fe7-974fa58bf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose one numeric and one categorical column to demonstrate\n",
    "demo_numeric_col = \"beds\"\n",
    "demo_categorical_col = \"furnishing\"\n",
    "\n",
    "# Get indices where these columns have missing values\n",
    "num_missing_idx = df[df[demo_numeric_col].isna()].head(5).index\n",
    "cat_missing_idx = df[df[demo_categorical_col].isna()].head(5).index\n",
    "\n",
    "# Combine indices (avoid duplicates)\n",
    "demo_idx = num_missing_idx.union(cat_missing_idx)\n",
    "\n",
    "# BEFORE imputation (original dataframe)\n",
    "print(\"Rows BEFORE imputation\")\n",
    "display(df.loc[demo_idx])\n",
    "\n",
    "# AFTER imputation (reconstructed dataframe)\n",
    "df_after_demo = df.copy()\n",
    "df_after_demo.loc[:, numeric_cols] = df_num_demo\n",
    "df_after_demo.loc[:, cat_cols] = df_cat_demo\n",
    "\n",
    "print(\"Rows AFTER imputation\")\n",
    "display(df_after_demo.loc[demo_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ff076",
   "metadata": {},
   "source": [
    "## 4) Summary statistics\n",
    "\n",
    "We inspect numeric summaries to spot outliers and scale differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics (styled)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "summary = df.describe(include=\"all\").transpose()\n",
    "# Show a compact view first (top rows) then let user scroll in output if needed\n",
    "display(\n",
    "    summary.style\n",
    "        .set_caption(\"Summary statistics (all columns)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740b279",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> - Rent often has a long right tail (premium listings).\n",
    "> - Outliers can dominate RMSE.\n",
    "> - Category counts can be unbalanced (some cities have far more listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbd8aa",
   "metadata": {},
   "source": [
    "## 5) Split data into train / validation / test\n",
    "\n",
    "We use three splits:\n",
    "- **train** (60%) : fit the model  \n",
    "- **validation** (20%): compare models / choices  \n",
    "- **test** (20%) : final unbiased evaluation  \n",
    "\n",
    "We keep the test set untouched until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split gives a reproducible split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "\n",
    "X = df.drop(columns=[\"rent\"])\n",
    "y = df[\"rent\"]\n",
    "\n",
    "# 20% test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# From remaining 80%, take 25% as validation -> 20% overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "split_sizes = pd.DataFrame(\n",
    "    {\n",
    "        \"rows\": [len(X_train), len(X_val), len(X_test)],\n",
    "        \"share\": [len(X_train)/len(df), len(X_val)/len(df), len(X_test)/len(df)],\n",
    "    },\n",
    "    index=[\"train\", \"validation\", \"test\"]\n",
    ")\n",
    "split_sizes[\"share\"] = (split_sizes[\"share\"] * 100).round(1).astype(str) + \"%\"\n",
    "display(split_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedab43",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - This is a safe pattern: we do not tune on the test set.\n",
    "> - Validation is where we compare models.\n",
    "> - We might want to do different split options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462f066",
   "metadata": {},
   "source": [
    "## 6) Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA builds intuition.\n",
    "We ask:\n",
    "- What does rent look like?\n",
    "- Which numeric features move rent?\n",
    "- How do cities and furnishing levels differ?\n",
    "\n",
    "We will use **Seaborn** for cleaner, more â€œreport-likeâ€ visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50350df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn sits on top of Matplotlib and gives nicer default plots.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def format_inr(x, pos=None):\n",
    "    try:\n",
    "        return \"â‚¹ {:,}\".format(int(x))\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "inr_formatter = FuncFormatter(format_inr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e892e5",
   "metadata": {},
   "source": [
    "### 6.1 Distribution of rent (histogram + box)\n",
    "\n",
    "- histogram for shape\n",
    "- boxplot for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe45a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(11, 6))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[4, 1], hspace=0.05)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1], sharex=ax1)\n",
    "\n",
    "# Matplotlib histogram (avoids seaborn/pandas option incompatibilities)\n",
    "ax1.hist(y_train, bins=50)\n",
    "ax1.set_title(\"Distribution of Monthly Rent (Train Set)\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.xaxis.set_major_formatter(inr_formatter)\n",
    "\n",
    "sns.boxplot(x=y_train, ax=ax2)\n",
    "ax2.set_xlabel(\"Monthly Rent (â‚¹)\")\n",
    "ax2.xaxis.set_major_formatter(inr_formatter)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417dd9c5",
   "metadata": {},
   "source": [
    "> **Inference**\n",
    "> - The distribution is right-skewed. A few premium rentals exist.\n",
    "> - The boxplot makes outliers obvious.\n",
    "> - RMSE will be sensitive to extreme rents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a15c88",
   "metadata": {},
   "source": [
    "### 6.2 Numeric features vs rent\n",
    "\n",
    "We plot rent against each numeric feature.\n",
    "We also add a trend line to make the direction clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b4b17-7219-4a6d-bb5a-391ae523ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "\n",
    "# Plot in a grid to reduce scrolling\n",
    "n = len(numeric_cols)\n",
    "ncols = 2 if n > 1 else 1\n",
    "nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(12, 4.8 * nrows),\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "for ax, col in zip(axes, numeric_cols):\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        y=\"rent\",\n",
    "        alpha=0.25,\n",
    "        s=18,\n",
    "        color=\"#F58518\",\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.yaxis.set_major_formatter(inr_formatter)\n",
    "    ax.set_title(f\"{col} vs Rent\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Monthly Rent (â‚¹)\")\n",
    "\n",
    "# Hide unused axes\n",
    "for ax in axes[len(numeric_cols):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0155f25-ef98-43e7-be52-575190ddf4ac",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - `area` typically shows the clearest upward trend.\n",
    "> - Discrete counts (`beds`, `bathrooms`) create â€œbandsâ€."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44372daf",
   "metadata": {},
   "source": [
    "### 6.2.1 A 3D view (rent vs area vs area_rate)\n",
    "\n",
    "A 3D scatter can be a fun way to see how **two** inputs relate to rent at the same time.\n",
    "Use it for intuition, not for precise conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd44e9-c5f6-415d-a645-c5c762eb955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.io as pio\n",
    "\n",
    "print(\"Plotly version:\", plotly.__version__)\n",
    "print(\"Available renderers:\", pio.renderers)\n",
    "\n",
    "# Best defaults for JupyterLab:\n",
    "# Try one of these (first one usually works)\n",
    "#pio.renderers.default = \"notebook_connected\"   # good for JupyterLab + classic\n",
    "#pio.renderers.default = \"jupyterlab\"         # works in some setups\n",
    "pio.renderers.default = \"iframe\"             # always works, slightly heavier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d595d-81f1-4b48-8d52-c3bf901c73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Prepare clean data for 3D visualization\n",
    "cols3d = [\"area\", \"area_rate\", \"rent\"]\n",
    "df3d = df[cols3d + [\"city\"]].dropna().copy()\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df3d,\n",
    "    x=\"area\",\n",
    "    y=\"area_rate\",\n",
    "    z=\"rent\",\n",
    "    color=\"city\",                     # remove this line if you want single-color points\n",
    "    opacity=0.5,\n",
    "    title=\"3D View: Area vs Area Rate vs Rent\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Area (sqft)\",\n",
    "        yaxis_title=\"Area Rate\",\n",
    "        zaxis_title=\"Monthly Rent (â‚¹)\",\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3a896",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Listings with similar area can have very different rent if the area rate differs.\n",
    "> - This supports why both `area` and `area_rate` can be useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b69fa",
   "metadata": {},
   "source": [
    "### 6.3 Categorical overview (counts)\n",
    "\n",
    "We check how many categories exist.\n",
    "Then we visualize the top counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Explicitly include both legacy object and new string dtypes\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "cardinality = (\n",
    "    pd.DataFrame({\n",
    "        \"column\": categorical_cols,\n",
    "        \"unique_categories\": [df[c].nunique(dropna=True) for c in categorical_cols]\n",
    "    })\n",
    "    .sort_values(\"unique_categories\", ascending=False)\n",
    ")\n",
    "\n",
    "display(\n",
    "    cardinality.style\n",
    "        .format({\"unique_categories\": \"{:,}\"})\n",
    "        .bar(subset=[\"unique_categories\"], align=\"mid\")\n",
    "        .set_caption(\"Category counts (unique values)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f8fdd",
   "metadata": {},
   "source": [
    "> **Inference**\n",
    "> - `city` and `furnishing` are low-cardinality. They are great for one-hot encoding.\n",
    "> - `locality` can have many categories. We will skip it in the first baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406354f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_cities = (\n",
    "    df[\"city\"]\n",
    "    .value_counts()\n",
    "    .head(12)\n",
    "    .reset_index()\n",
    ")\n",
    "top_cities.columns = [\"city\", \"count\"]\n",
    "\n",
    "# Plot in a grid to reduce scrolling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5.5), constrained_layout=True)\n",
    "\n",
    "sns.barplot(\n",
    "    data=top_cities,\n",
    "    x=\"city\",\n",
    "    y=\"count\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Top Cities by Listing Count\")\n",
    "axes[0].set_xlabel(\"City\")\n",
    "axes[0].set_ylabel(\"Number of Listings\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=25)\n",
    "\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=\"furnishing\",\n",
    "    order=df[\"furnishing\"].value_counts().index,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Furnishing Distribution\")\n",
    "axes[1].set_xlabel(\"Furnishing\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=15)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66efdf",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - If one city dominates, the model may become city-biased.\n",
    "> - Later, check error by city.\n",
    "> - Furnishing often shifts the rent baseline. This is a strong reason to keep it as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9919d7",
   "metadata": {},
   "source": [
    "### 6.4 Rent by category (boxplots)\n",
    "\n",
    "Boxplots show how rent spreads across categories.\n",
    "We plot the top cities for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4edfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "categorical_cols = [\"city\", \"furnishing\"]\n",
    "categorical_cols = [c for c in categorical_cols if c in df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(categorical_cols), figsize=(14, 5), constrained_layout=True)\n",
    "\n",
    "# Handle single-plot case\n",
    "if len(categorical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, col in zip(axes, categorical_cols):\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        y=\"rent\",\n",
    "        hue=col,\n",
    "        palette=\"pastel\",\n",
    "        showfliers=False,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.yaxis.set_major_formatter(inr_formatter)\n",
    "    ax.set_title(f\"Rent Distribution by {col}\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Monthly Rent (â‚¹)\")\n",
    "    ax.tick_params(axis=\"x\", rotation=25)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7926b86",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> - Some cities have a clearly higher rent range.\n",
    "> - A global model needs to learn both city-level shifts and within-city trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19624f58",
   "metadata": {},
   "source": [
    "## Key insights from EDA\n",
    "\n",
    "Before we model, we write down a few observations from the charts.\n",
    "This keeps the workflow realistic: **EDA should influence decisions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d225b",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Note the top cities. A model may learn dominant cities better than rare ones.\n",
    "> - Compare median rent across furnishing levels. If the gaps are large, furnishing should help prediction.\n",
    "> - Check which numeric feature correlates most with rent (often `area` or `area_rate`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a881f15",
   "metadata": {},
   "source": [
    "## 7) Correlation: Understanding Relationships Between Features\n",
    "\n",
    "Correlation is a quick way to rank numeric relationships. \n",
    "\n",
    "**Correlation** measures how strongly two numeric variables move **together**.\n",
    "\n",
    "* A **positive correlation** means both variables increase together\n",
    "* A **negative correlation** means one increases while the other decreases\n",
    "* A correlation close to **0** means little or no linear relationship\n",
    "\n",
    "Correlation values typically range from **-1 to +1**.\n",
    "\n",
    "### How Correlation Is Computed (Intuition)\n",
    "\n",
    "For numeric features, correlation compares:\n",
    "\n",
    "* how much each value deviates from its mean\n",
    "* whether those deviations move in the same or opposite direction\n",
    "\n",
    "In practice, we commonly use **Pearson correlation**, which captures **linear relationships** between variables.\n",
    "\n",
    "### Why We Look at Correlation\n",
    "\n",
    "Correlation helps us:\n",
    "\n",
    "* understand which features are related to the target\n",
    "* detect redundant or highly related features\n",
    "* get an early sense of which variables may be useful for modeling\n",
    "\n",
    "> Correlation does **not** imply causation â€” itâ€™s an exploratory signal, not a conclusion.\n",
    "\n",
    "### What Weâ€™ll Do Next\n",
    "\n",
    "We will compute **correlation among numeric features**, including the target (`rent`), and visualize it to better understand their relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57404be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with rent (numeric only)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "corr = df[numeric_cols + [\"rent\"]].corr(numeric_only=True)\n",
    "\n",
    "corr_with_rent = corr[\"rent\"].drop(\"rent\").sort_values(ascending=False).reset_index()\n",
    "corr_with_rent.columns = [\"feature\", \"correlation_with_rent\"]\n",
    "\n",
    "display(\n",
    "    corr_with_rent.style\n",
    "        .format({\"correlation_with_rent\": \"{:.3f}\"})\n",
    "        .bar(subset=[\"correlation_with_rent\"], align=\"mid\")\n",
    "        .set_caption(\"Numeric correlation with rent (higher magnitude â†’ stronger linear relationship)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62e843",
   "metadata": {},
   "source": [
    "### 7.1 Correlation heatmap (numeric features)\n",
    "\n",
    "A heatmap makes correlation patterns easier to scan.\n",
    "We only include numeric columns here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A heatmap is a compact way to view correlations.\n",
    "# We keep it to numeric columns to avoid mixing types.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar=True)\n",
    "plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769d2de",
   "metadata": {},
   "source": [
    "## 8) Feature selection (baseline model)\n",
    "\n",
    "We start with a small, stable set of features.\n",
    "\n",
    "We use:\n",
    "- numeric: `area`, `beds`, `bathrooms`, `balconies`, `area_rate`\n",
    "- categorical: `city`, `furnishing`\n",
    "\n",
    "We skip for now:\n",
    "- `locality` (high-cardinality)\n",
    "- `house_type` (free text)\n",
    "\n",
    "Future idea:\n",
    "- Use `locality` to map to a **pincode** or zone, then use grouped features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8751f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "cat_features = [\"city\", \"furnishing\"]\n",
    "\n",
    "X_train_sel = X_train[num_features + cat_features].copy()\n",
    "X_val_sel   = X_val[num_features + cat_features].copy()\n",
    "X_test_sel  = X_test[num_features + cat_features].copy()\n",
    "\n",
    "X_train_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1b03d",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Baselines should be simple and explainable.\n",
    "> - You can add complexity later once you trust the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26644f34",
   "metadata": {},
   "source": [
    "## 9) Preprocessing with pipelines (imputation + one-hot)\n",
    "\n",
    "A pipeline chains steps safely.\n",
    "It also avoids data leakage.\n",
    "\n",
    "Our preprocessor will:\n",
    "- impute numeric missing values with the **mean**\n",
    "- impute categorical missing values with the **most frequent**\n",
    "- one-hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipeline, num_features),\n",
    "    (\"cat\", categorical_pipeline, cat_features),\n",
    "])\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab566f8",
   "metadata": {},
   "source": [
    "### 9.1 One-hot encoding (how the data looks)\n",
    "\n",
    "One-hot encoding turns each category into its own binary (0/1) column.  \n",
    "This lets linear and tree-based models work with categorical inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f693629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Show a tiny sample BEFORE encoding (raw categorical columns present)\n",
    "sample_before = X_train_sel.head(3).copy()\n",
    "display(sample_before)\n",
    "\n",
    "# Fit the preprocessing on training data and show a small AFTER view\n",
    "X_after = preprocess.fit_transform(X_train_sel)\n",
    "\n",
    "# Build readable feature names (numeric + one-hot category names)\n",
    "ohe = preprocess.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "ohe_feature_names = ohe.get_feature_names_out(cat_features)\n",
    "\n",
    "feature_names = list(num_features) + list(ohe_feature_names)\n",
    "\n",
    "# Convert a small slice to a DataFrame for display\n",
    "sample_after = pd.DataFrame(X_after[:3], columns=feature_names)\n",
    "display(sample_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4102445",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - We do not clean the DataFrame by hand.\n",
    "> - The pipeline learns imputation values from training data only.\n",
    "> - `handle_unknown=\"ignore\"` makes inference safer if a new city appears later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce9448",
   "metadata": {},
   "source": [
    "## 10) Cross-validation (CV) for model comparison\n",
    "\n",
    "Cross-validation trains the model multiple times on different folds of the training set.\n",
    "This reduces the risk of a lucky or unlucky split.\n",
    "\n",
    "We compare three models:\n",
    "\n",
    "| Model                       | What is it?                                           | Key Idea                                                  | What it Optimizes                              | When It Works Well                                                 |\n",
    "| --------------------------- | ----------------------------------------------------- | --------------------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------------ |\n",
    "| **Linear Regression**       | Models the target as a weighted sum of input features | Assumes a linear relationship between features and target | Minimizes Mean Squared Error (MSE)             | When relationships are roughly linear and features are informative |\n",
    "| **Ridge Regression**        | Linear Regression with coefficient regularization     | Penalizes large coefficients to reduce overfitting        | MSE + L2 penalty on coefficients               | When features are correlated or feature space is high-dimensional  |\n",
    "| **Decision Tree Regressor** | Learns a set of ifâ€“else rules to make predictions     | Recursively splits data to reduce prediction error        | Reduces variance (squared error) at each split | When relationships are non-linear or feature interactions matter   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d71078-9cf6-4eae-b3ea-605108b593ae",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ“ Regression Evaluation Metrics\n",
    "\n",
    "| Metric                        | What It Measures                                                  | Interpretation                                  |\n",
    "| ----------------------------- | ----------------------------------------------------------------- | ----------------------------------------------- |\n",
    "| **MAE** (Mean Absolute Error) | Average absolute difference between predictions and actual values | Easy to interpret, same units as the target (â‚¹) |\n",
    "| **MSE** (Mean Squared Error)  | Average of squared prediction errors                              | Penalizes large errors more heavily             |\n",
    "| **RÂ²** (R-squared)            | How much of the variation in the target is explained by the model | Closer to 1 means better explanatory power      |\n",
    "\n",
    "\n",
    "### Quick Notes\n",
    "\n",
    "* **MAE** â†’ â€œOn average, how wrong are we?â€\n",
    "* **MSE** â†’ â€œHow bad are large mistakes?â€\n",
    "* **RÂ²** â†’ â€œHow well does the model explain the data?â€\n",
    "\n",
    "> Always look at **error metrics (MAE/MSE)** along with **RÂ²**.\n",
    "\n",
    "If you want an even tighter 2-row version or a spoken-script version, I can do that too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb16d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145b6d-f80a-4c23-8512-36bc5452d4e0",
   "metadata": {},
   "source": [
    "### Cross-Validation (Why We Use It)\n",
    "\n",
    "Cross-validation helps us **estimate how well a model will perform on unseen data**.\n",
    "\n",
    "Instead of training and evaluating the model on a single split:\n",
    "\n",
    "* the data is split into multiple folds\n",
    "* the model is trained and evaluated multiple times\n",
    "* results are averaged for a more reliable estimate\n",
    "\n",
    "This reduces the risk of:\n",
    "\n",
    "* depending too much on one lucky (or unlucky) split\n",
    "* overestimating model performance\n",
    "\n",
    "> Cross-validation gives a **more stable and trustworthy evaluation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad60839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "candidates = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge(alpha=1.0)\": Ridge(alpha=1.0),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "def cv_mae_scores(model, X, y):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    return -scores  # convert to positive MAE\n",
    "\n",
    "cv_scores = {name: cv_mae_scores(model, X_train_sel, y_train) for name, model in candidates.items()}\n",
    "\n",
    "cv_scores_df = pd.DataFrame(cv_scores)\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"MAE (mean)\": cv_scores_df.mean().astype(float),\n",
    "        \"MAE (std)\": cv_scores_df.std(ddof=0).astype(float),\n",
    "    }\n",
    ").sort_values(\"MAE (mean)\")\n",
    "\n",
    "display(cv_scores_df.style.format(precision=2))\n",
    "display(summary.style.format(precision=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba6d31",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - You see fold-by-fold RMSE for each model.\n",
    "> - Lower MAE is better.\n",
    "> - High spread across folds means instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV score distributions (long-form)\n",
    "cv_long = cv_scores_df.melt(var_name=\"model\", value_name=\"mae\")\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "ax = sns.boxplot(data=cv_long, x=\"model\", y=\"mae\", hue=\"model\", palette=\"Set3\")\n",
    "if ax.get_legend() is not None:\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "plt.title(\"Cross-Validation MAE by Model (Train Set)\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f692391",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Prefer models with low mean RMSE and low variance.\n",
    "> - Trees can overfit and show higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d9bc4",
   "metadata": {},
   "source": [
    "## 11) Train each model and evaluate on the validation set\n",
    "\n",
    "Now we train on the training split once.\n",
    "Then we score on the validation split.\n",
    "This is a realistic model-selection loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd241314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def train_and_eval(model, X_tr, y_tr, X_eval, y_eval):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    preds = pipe.predict(X_eval)\n",
    "    mae = float(mean_absolute_error(y_eval, preds))\n",
    "    r2 = float(r2_score(y_eval, preds))\n",
    "    return pipe, preds, mae, r2\n",
    "\n",
    "val_results = []\n",
    "val_preds = {}\n",
    "trained = {}\n",
    "\n",
    "for name, model in candidates.items():\n",
    "    pipe, preds, mae, r2 = train_and_eval(model, X_train_sel, y_train, X_val_sel, y_val)\n",
    "    trained[name] = pipe\n",
    "    val_preds[name] = preds\n",
    "    val_results.append((name, mae, r2))\n",
    "\n",
    "val_table = pd.DataFrame(val_results, columns=[\"model\", \"val_MAE\", \"val_R2\"]).sort_values(\"val_MAE\")\n",
    "display(val_table.style.format({\"val_MAE\": \"{:.2f}\", \"val_R2\": \"{:.3f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdeb2db",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - Validation MAE is easiest to interpret in â‚¹.\n",
    "> - RÂ² is a sanity check. Do not optimize for it blindly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9688cfa",
   "metadata": {},
   "source": [
    "### 11.1 Validation residuals (per model)\n",
    "\n",
    "Residual = actual âˆ’ predicted.\n",
    "We want residuals centered around 0 with reasonable spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for name, preds in val_preds.items():\n",
    "    if (name == 'LinearRegression') or (name == 'DecisionTree') or (name == 'Ridge(alpha=1.0)'):\n",
    "        residuals = y_val.values - preds\n",
    "        plt.hist(residuals, bins=35, histtype=\"step\", linewidth=2, label=name)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(\"Validation Residual Distributions (Actual âˆ’ Predicted)\")\n",
    "plt.xlabel(\"Residual (â‚¹)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1e966",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> - Narrower residual distributions usually mean lower error.\n",
    "> - Long tails usually come from premium listings and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7524a",
   "metadata": {},
   "source": [
    "## 12) Pick the best model and evaluate on the test set\n",
    "\n",
    "We pick the model with the best validation RMSE.\n",
    "Then we refit it on train + validation.\n",
    "Finally, we evaluate once on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name, best_mae, best_r2 = val_table.iloc[0][\"model\"], float(val_table.iloc[0][\"val_MAE\"]), float(val_table.iloc[0][\"val_R2\"])\n",
    "\n",
    "best_summary = pd.DataFrame(\n",
    "    [{\"best_model\": best_name, \"best_val_MAE\": best_mae, \"best_val_R2\": best_r2}]\n",
    ")\n",
    "display(best_summary.style.format({\"best_val_MAE\": \"{:.2f}\", \"best_val_R2\": \"{:.3f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d413a9",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - After this point, we stop comparing models.\n",
    "> - The test set is used only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = candidates[best_name]\n",
    "\n",
    "X_trainval_sel = X_trainval[num_features + cat_features].copy()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "final_pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", best_model)])\n",
    "final_pipe.fit(X_trainval_sel, y_trainval)\n",
    "\n",
    "test_preds = final_pipe.predict(X_test_sel)\n",
    "\n",
    "test_mae = float(mean_absolute_error(y_test, test_preds))\n",
    "test_r2 = float(r2_score(y_test, test_preds))\n",
    "\n",
    "test_summary = pd.DataFrame(\n",
    "    [{\"model\": best_name, \"test_MAE\": test_mae, \"test_R2\": test_r2}]\n",
    ")\n",
    "display(test_summary.style.format({\"test_MAE\": \"{:.2f}\", \"test_R2\": \"{:.3f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0fee62",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> - This test RMSE is your final unbiased estimate.\n",
    "> - Do not tune hyperparameters using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ad95c",
   "metadata": {},
   "source": [
    "## 13) Error analysis on the test set\n",
    "\n",
    "We inspect:\n",
    "- residual distribution\n",
    "- biggest mistakes (largest absolute error)\n",
    "- average error by city (quick check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d648b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_residuals = y_test.values - test_preds\n",
    "\n",
    "plt.figure(figsize=(11, 5.5))\n",
    "plt.hist(test_residuals, bins=40)\n",
    "plt.gca().xaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(\"Test Residual Distribution (Actual âˆ’ Predicted)\")\n",
    "plt.xlabel(\"Residual (â‚¹)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6a32c",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - If residuals are shifted left or right, the model is biased.\n",
    "> - Wide spread means the model is not precise.\n",
    "> - Long tails indicate outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65387ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest errors (top 15)\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reconstruct the error table explicitly (safe if cells are run out of order)\n",
    "errors = X_test_sel.copy()\n",
    "errors[\"actual_rent\"] = y_test.values\n",
    "errors[\"predicted_rent\"] = test_preds\n",
    "errors[\"abs_error\"] = np.abs(errors[\"actual_rent\"] - errors[\"predicted_rent\"])\n",
    "\n",
    "top_err = errors.sort_values(\"abs_error\", ascending=False).head(15).copy()\n",
    "\n",
    "display(\n",
    "    top_err.style\n",
    "        .format({\n",
    "            \"actual_rent\": \"â‚¹ {:,.0f}\",\n",
    "            \"predicted_rent\": \"â‚¹ {:,.0f}\",\n",
    "            \"abs_error\": \"â‚¹ {:,.0f}\",\n",
    "        })\n",
    "        .bar(subset=[\"abs_error\"], align=\"mid\")\n",
    "        .set_caption(\"Largest absolute errors on the test set\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc0576",
   "metadata": {},
   "source": [
    "> **Notes**\n",
    "> - This table is actionable.\n",
    "> - It shows which listings need better features or a stronger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14184c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"city\" in errors.columns:\n",
    "    city_mae = (\n",
    "        errors.groupby(\"city\")[\"abs_error\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10.5, 5.5))\n",
    "    sns.barplot(\n",
    "        x=city_mae.index[:10],\n",
    "        y=city_mae.values[:10],\n",
    "        hue=city_mae.index[:10],   # explicitly map color\n",
    "        palette=\"magma\",\n",
    "        legend=False               # avoid redundant legend\n",
    "    )\n",
    "    plt.gca().yaxis.set_major_formatter(inr_formatter)\n",
    "    plt.title(\"Average Absolute Error by City â€” Test Set\")\n",
    "    plt.xlabel(\"City\")\n",
    "    plt.ylabel(\"Avg Absolute Error (â‚¹)\")\n",
    "    plt.xticks(rotation=25, ha=\"right\")\n",
    "    plt.show()\n",
    "\n",
    "    city_mae.head(10)\n",
    "\n",
    "# Also show the table for quick reading\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "city_mae_table = city_mae.head(10).reset_index()\n",
    "city_mae_table.columns = [\"city\", \"avg_abs_error\"]\n",
    "\n",
    "display(\n",
    "    city_mae_table.style\n",
    "        .format({\"avg_abs_error\": \"â‚¹ {:,.0f}\"})\n",
    "        .bar(subset=[\"avg_abs_error\"], align=\"mid\")\n",
    "        .set_caption(\"Avg absolute error by city (top 10) â€” test set\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7209345",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> - If one city has much higher error, you may need more data or better features for that city.\n",
    "> - This is a common production issue for geo-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c7a26",
   "metadata": {},
   "source": [
    "## 14) Recap and next steps\n",
    "\n",
    "We built a realistic ML workflow:\n",
    "- EDA with readable plots\n",
    "- explicit missing data handling section\n",
    "- train / validation / test split\n",
    "- preprocessing pipeline (impute + one-hot)\n",
    "- model comparison using cross-validation\n",
    "- final evaluation on the test set\n",
    "- error analysis\n",
    "\n",
    "**Next steps**\n",
    "- Try stronger models (RandomForest, GradientBoosting)\n",
    "- Engineer features (log(rent), rent per sqft)\n",
    "- Add locality carefully (high-cardinality strategies)\n",
    "- Map locality to zones/pincodes for richer location signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0431ed2-d4ea-49ed-9e85-6e2c901a2cfa",
   "metadata": {},
   "source": [
    "## Saving the Best Model (Deployment Prep)\n",
    "\n",
    "Training a model is only half the job â€” **deployment is where most real work happens**.\n",
    "Typically you must ensure:\n",
    "- the **same preprocessing** runs in production\n",
    "- requests are handled with **reliability and low latency**\n",
    "- the system supports **monitoring, drift detection, and retraining**\n",
    "- the service is **versioned, tested, and scalable** (MLOps)\n",
    "\n",
    "Next, weâ€™ll save the **full pipeline (preprocess + model)** so it can be loaded directly in a FastAPI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c9c7-078f-40b4-8f3e-68aa03467444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 1) Choose the best model (set this based on your selection)\n",
    "# Example:\n",
    "# best_model = Ridge(alpha=1.0)\n",
    "# best_model = DecisionTreeRegressor(max_depth=6, random_state=42)\n",
    "\n",
    "# 2) Build the full pipeline (preprocess + model)\n",
    "best_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", best_model),\n",
    "])\n",
    "\n",
    "# 3) Fit on training data (or train+val if you decide later)\n",
    "best_pipeline.fit(X_train_sel, y_train)\n",
    "\n",
    "# 4) Save to disk\n",
    "artifacts_dir = Path(\"artifacts\")\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = artifacts_dir / f\"rent_model_pipeline_{timestamp}.joblib\"\n",
    "\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "\n",
    "print(f\"âœ… Saved model pipeline to: {model_path}\")\n",
    "print(\"Includes preprocessing + model (ready to load in FastAPI).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b6feb-dc27-447c-8380-40d788e6f833",
   "metadata": {},
   "source": [
    "### Quick â€œload and predictâ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b8178-4fb7-4ecb-a3d1-535e193ebfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load(model_path)\n",
    "sample_preds = loaded.predict(X_train_sel.head(3))\n",
    "print(sample_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359f002-8f39-4fa3-9ad0-7f2b6126baf4",
   "metadata": {},
   "source": [
    "## ðŸ§  Optional: Interpreting the Decision Tree Model\n",
    "\n",
    "At this point, we have a trained pipeline that includes both:\n",
    "- preprocessing (imputation + one-hot encoding)\n",
    "- the final Decision Tree model\n",
    "\n",
    "In this optional section, we inspect **feature importance** to understand:\n",
    "- which inputs have the biggest impact on predictions\n",
    "- why changing some inputs (e.g., `city`) may not change the predicted rent\n",
    "\n",
    "Note: With one-hot encoding, a single categorical feature (like `city`) becomes many binary columns.\n",
    "So we will look at importance in two ways:\n",
    "1. top transformed features (after preprocessing)\n",
    "2. importance aggregated back to the original feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415308c-3ccc-4fdb-b347-cf4754728ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Extract fitted preprocessing + trained tree from your pipeline ---\n",
    "preprocess_fitted = best_pipeline.named_steps[\"preprocess\"]\n",
    "tree = best_pipeline.named_steps[\"model\"]\n",
    "\n",
    "# --- Get feature names after preprocessing and importance scores ---\n",
    "feature_names = preprocess_fitted.get_feature_names_out()\n",
    "importances = tree.feature_importances_\n",
    "\n",
    "feature_importance_df = (\n",
    "    pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Top 15 transformed features used by the tree:\")\n",
    "display(feature_importance_df.head(15))\n",
    "\n",
    "# --- Correctly map transformed feature names back to original features ---\n",
    "# Remove \"num__\" / \"cat__\" prefix\n",
    "clean = feature_importance_df[\"feature\"].str.replace(r\"^(num__|cat__)\", \"\", regex=True)\n",
    "\n",
    "def base_feature_name(transformed_name: str, cat_cols) -> str:\n",
    "    \"\"\"\n",
    "    Map names like:\n",
    "      - city_Bangalore -> city\n",
    "      - furnishing_Fully Furnished -> furnishing\n",
    "      - area_rate -> area_rate  (do NOT split numeric names with underscores)\n",
    "    \"\"\"\n",
    "    for c in cat_cols:\n",
    "        if transformed_name == c or transformed_name.startswith(c + \"_\"):\n",
    "            return c\n",
    "    return transformed_name\n",
    "\n",
    "# cat_features should already exist in your notebook; if not, define it consistently\n",
    "# cat_features = [\"city\", \"furnishing\"]  # example\n",
    "feature_importance_df[\"base_feature\"] = clean.apply(lambda s: base_feature_name(s, cat_features))\n",
    "\n",
    "# --- Aggregate importance back to original feature level ---\n",
    "grouped_importance = (\n",
    "    feature_importance_df.groupby(\"base_feature\")[\"importance\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Total importance by original feature:\")\n",
    "display(grouped_importance.to_frame(\"total_importance\"))\n",
    "\n",
    "# --- Plot top 10 original features ---\n",
    "top_k = 10\n",
    "grouped_importance.head(top_k).sort_values().plot(kind=\"barh\", figsize=(8, 4))\n",
    "plt.title(\"Decision Tree Feature Importance (Aggregated)\")\n",
    "plt.xlabel(\"Total Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539d312-d25a-4bee-8694-231e145064af",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Key Takeaway\n",
    "\n",
    "> Feature importance tells us what the **model learned**,\n",
    "> not what we **assumed** would be important.\n",
    "\n",
    "This step helps us:\n",
    "\n",
    "* trust the model\n",
    "* explain predictions\n",
    "* identify missing or redundant features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
