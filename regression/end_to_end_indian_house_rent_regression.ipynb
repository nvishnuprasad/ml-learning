{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370d7d9b",
   "metadata": {},
   "source": [
    "# End-to-End Machine Learning Project (Regression)\n",
    "## Predicting House Rent in Indian Cities\n",
    "\n",
    "We will build a model that predicts **monthly rent** from rental listing attributes.\n",
    "\n",
    "This notebook is practical and step-by-step.\n",
    "After most code cells, you will see a short **inference** section.\n",
    "It tells you what to observe and what not to over-interpret.\n",
    "\n",
    "**Workflow**\n",
    "1. Load and inspect data  \n",
    "2. Explore patterns (EDA)  \n",
    "3. Split into train / validation / test  \n",
    "4. Prepare data with pipelines (missing values + one-hot)  \n",
    "5. Compare models with cross-validation  \n",
    "6. Select a final model and evaluate on the test set  \n",
    "7. Analyze errors and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5438ed",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "We load the CSV into a Pandas DataFrame.\n",
    "Then we preview a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc135a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is the standard library for tabular data in Python.\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = r\"data/cities_magicbricks_rental_prices.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b51f2",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- `rent` is the target. It is a continuous number, so this is a regression task.\n",
    "- We have numeric features (`area`, `beds`, …) and categorical features (`city`, `furnishing`).\n",
    "- `house_type` is long text. We will skip it in the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441648b",
   "metadata": {},
   "source": [
    "## 2) Quick data checks\n",
    "\n",
    "We inspect:\n",
    "- number of rows and columns\n",
    "- data types\n",
    "- missing values\n",
    "\n",
    "This tells us what preprocessing we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726c546",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- More rows usually means more stable model comparisons.\n",
    "- If your dataset is tiny, cross-validation results can swing a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17c88a",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Categorical columns show up as `object`.\n",
    "- Numeric columns show up as `int64` or `float64`.\n",
    "- You should see a small amount of missing values.\n",
    "  We injected them on purpose so we can demonstrate imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbfed9",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Missing values are scattered, not nicely grouped.\n",
    "- This is common in real data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e79c37",
   "metadata": {},
   "source": [
    "## 3) Summary statistics\n",
    "\n",
    "We look at numeric summaries.\n",
    "This helps us spot scale differences and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b2194",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Rent usually has a long right tail (premium listings).\n",
    "- Outliers can dominate error metrics like RMSE.\n",
    "- Category counts can be unbalanced (some cities have more listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ad2bd",
   "metadata": {},
   "source": [
    "## 4) Split into train / validation / test\n",
    "\n",
    "We use three splits:\n",
    "- **train**: fit model parameters\n",
    "- **validation**: compare choices (model selection)\n",
    "- **test**: final unbiased evaluation\n",
    "\n",
    "We do not touch the test set until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split gives a clean and reproducible split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"rent\"])\n",
    "y = df[\"rent\"]\n",
    "\n",
    "# 20% test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# From the remaining 80%, make 25% validation -> 20% overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9d3d9",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- This is a safe pattern: test is held out early and never reused.\n",
    "- Validation is where we compare models.\n",
    "- Fixing `random_state` makes your demo repeatable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c94a6",
   "metadata": {},
   "source": [
    "## 5) Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA builds intuition.\n",
    "We ask:\n",
    "- What does rent look like?\n",
    "- Which features have a visible relationship with rent?\n",
    "- How do categories like city and furnishing differ?\n",
    "\n",
    "We format currency as Indian Rupees (₹)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib is a common plotting library.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def format_inr(x, pos=None):\n",
    "    # Example: ₹ 1,20,000\n",
    "    try:\n",
    "        return \"₹ {:,}\".format(int(x))\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "inr_formatter = FuncFormatter(format_inr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6002",
   "metadata": {},
   "source": [
    "### 5.1 Rent distribution\n",
    "\n",
    "We plot a histogram of rent values.\n",
    "This shows skew and typical ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64214a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10.5, 5.5))\n",
    "plt.hist(y_train.dropna(), bins=45, color=\"#4C78A8\", edgecolor=\"white\", alpha=0.9)\n",
    "plt.gca().xaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(\"Rent Distribution (Train Set)\")\n",
    "plt.xlabel(\"Monthly Rent\")\n",
    "plt.ylabel(\"Number of Listings\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafb91f",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- A right-skew is normal in rent data.\n",
    "- RMSE is sensitive to the high-rent tail.\n",
    "- Do not assume “most rentals are expensive” just because the tail exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa48150",
   "metadata": {},
   "source": [
    "### 5.2 Numeric features vs rent\n",
    "\n",
    "We plot rent against each numeric feature.\n",
    "This makes trends and outliers visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeced169",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(9.5, 5.5))\n",
    "    plt.scatter(df[col], df[\"rent\"], alpha=0.25, s=20, color=\"#F58518\")\n",
    "    plt.gca().yaxis.set_major_formatter(inr_formatter)\n",
    "    plt.title(f\"{col} vs Rent\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Monthly Rent\")\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b74196",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- `area` usually shows the clearest upward trend.\n",
    "- Discrete counts (`beds`, `bathrooms`) create horizontal “bands”.\n",
    "- Outliers matter. They can drive model error and influence model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca9b08",
   "metadata": {},
   "source": [
    "### 5.3 Categorical overview\n",
    "\n",
    "First, we check how many unique categories exist.\n",
    "Then we visualize counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"city\", \"furnishing\", \"locality\"]\n",
    "categorical_cols = [c for c in categorical_cols if c in df.columns]\n",
    "\n",
    "{c: df[c].nunique(dropna=True) for c in categorical_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36351965",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- `city` and `furnishing` are low-cardinality. They are great for one-hot encoding.\n",
    "- `locality` can be high-cardinality. It can create many one-hot columns.\n",
    "- For a first model, we keep features simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dead7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts = df[\"city\"].value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.bar(city_counts.index.astype(str), city_counts.values, color=\"#54A24B\")\n",
    "plt.title(\"Top Cities by Listing Count\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Number of Listings\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01460d8",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- If one city dominates, the model can become “city-biased”.\n",
    "- Always check error by city later when you productionize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "furn_counts = df[\"furnishing\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8.5, 5.2))\n",
    "plt.bar(furn_counts.index.astype(str), furn_counts.values, color=\"#E45756\")\n",
    "plt.title(\"Furnishing Distribution\")\n",
    "plt.xlabel(\"Furnishing\")\n",
    "plt.ylabel(\"Number of Listings\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95177d5",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Furnishing is a strong “step feature” in rent.\n",
    "- This is a practical reason to keep categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637e675",
   "metadata": {},
   "source": [
    "### 5.4 Rent spread by category\n",
    "\n",
    "Boxplots show rent distributions by category.\n",
    "We plot top cities to keep the chart readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3703032",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = df[\"city\"].value_counts().head(8).index.tolist()\n",
    "df_top = df[df[\"city\"].isin(top_cities)].copy()\n",
    "\n",
    "groups = [df_top.loc[df_top[\"city\"] == c, \"rent\"].dropna().values for c in top_cities]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(\n",
    "    groups,\n",
    "    labels=top_cities,\n",
    "    showfliers=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"#72B7B2\", alpha=0.85),\n",
    "    medianprops=dict(color=\"#000000\"),\n",
    ")\n",
    "plt.gca().yaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(\"Rent Distribution by City (Top 8 Cities)\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Monthly Rent\")\n",
    "plt.xticks(rotation=25, ha=\"right\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1955bb8",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- City is not just noise. It shifts the entire rent range.\n",
    "- A single global model must learn both local and global patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c80bb",
   "metadata": {},
   "source": [
    "## 6) Correlation (numeric only)\n",
    "\n",
    "Correlation helps us rank numeric relationships quickly.\n",
    "It does not prove causation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[numeric_cols + [\"rent\"]].corr(numeric_only=True)\n",
    "corr[\"rent\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c6151",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- `area` and `area_rate` often rank high.\n",
    "- Categorical effects do not show here. Use boxplots for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a424825",
   "metadata": {},
   "source": [
    "## 7) Feature selection (first version)\n",
    "\n",
    "We start with a clean feature set.\n",
    "We keep it interpretable and stable.\n",
    "\n",
    "We will use:\n",
    "- numeric: `area`, `beds`, `bathrooms`, `balconies`, `area_rate`\n",
    "- categorical: `city`, `furnishing`\n",
    "\n",
    "We skip:\n",
    "- `house_type` (long text)\n",
    "- `locality` (can be high-cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"area\", \"beds\", \"bathrooms\", \"balconies\", \"area_rate\"]\n",
    "cat_features = [\"city\", \"furnishing\"]\n",
    "\n",
    "X_train_sel = X_train[num_features + cat_features].copy()\n",
    "X_val_sel   = X_val[num_features + cat_features].copy()\n",
    "X_test_sel  = X_test[num_features + cat_features].copy()\n",
    "\n",
    "X_train_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71087c",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Start simple. Then iterate.\n",
    "- If you add `locality`, re-check training time and feature explosion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b77cb",
   "metadata": {},
   "source": [
    "## 8) Preprocessing with pipelines\n",
    "\n",
    "A pipeline chains steps safely.\n",
    "It also avoids data leakage.\n",
    "\n",
    "We will build a **preprocessor**:\n",
    "- numeric: impute missing values using median\n",
    "- categorical: impute missing using most frequent, then one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae28571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipeline, num_features),\n",
    "    (\"cat\", categorical_pipeline, cat_features),\n",
    "])\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29149d8b",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- We do not “clean the DataFrame by hand”.\n",
    "- The pipeline learns imputation values from training data only.\n",
    "- One-hot makes categories usable for most ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a4229",
   "metadata": {},
   "source": [
    "## 9) Cross-validation (CV) for model comparison\n",
    "\n",
    "CV trains the model on multiple folds of the training set.\n",
    "It reduces the risk of a lucky/unlucky split.\n",
    "\n",
    "We will compare three models:\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Decision Tree Regressor\n",
    "\n",
    "We use RMSE as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86637a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "candidates = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge(alpha=1.0)\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "def cv_rmse_scores(model, X, y):\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\")\n",
    "    return -scores  # convert to positive RMSE\n",
    "\n",
    "cv_scores = {}\n",
    "for name, model in candidates.items():\n",
    "    cv_scores[name] = cv_rmse_scores(model, X_train_sel, y_train)\n",
    "\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baec758",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- You now see fold-by-fold RMSE for each model.\n",
    "- Lower RMSE is better.\n",
    "- High variation across folds suggests instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV RMSE distribution per model\n",
    "plt.figure(figsize=(10.5, 5.5))\n",
    "plt.boxplot(\n",
    "    [cv_scores[k] for k in cv_scores.keys()],\n",
    "    labels=list(cv_scores.keys()),\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"#9D755D\", alpha=0.75),\n",
    "    medianprops=dict(color=\"#000000\")\n",
    ")\n",
    "plt.title(\"Cross-Validation RMSE by Model (Train Set)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()\n",
    "\n",
    "# Show mean ± std\n",
    "[(k, float(np.mean(v)), float(np.std(v))) for k, v in cv_scores.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6125b",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- A model can have a low mean RMSE but high variance (risky choice).\n",
    "- Ridge often improves stability over plain Linear Regression.\n",
    "- Trees can overfit and show higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a277446",
   "metadata": {},
   "source": [
    "## 10) Train on train split and evaluate on validation split\n",
    "\n",
    "Cross-validation compares models inside the training data.\n",
    "Validation is a separate held-out set.\n",
    "It is a strong signal for model selection here.\n",
    "\n",
    "We train each model once on `train` and score on `validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae774462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate(model, X_tr, y_tr, X_eval, y_eval):\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    preds = pipe.predict(X_eval)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_eval, preds)))\n",
    "    r2 = float(r2_score(y_eval, preds))\n",
    "    return pipe, preds, rmse, r2\n",
    "\n",
    "val_results = []\n",
    "trained_pipes = {}\n",
    "val_preds = {}\n",
    "\n",
    "for name, model in candidates.items():\n",
    "    pipe, preds, rmse, r2 = evaluate(model, X_train_sel, y_train, X_val_sel, y_val)\n",
    "    trained_pipes[name] = pipe\n",
    "    val_preds[name] = preds\n",
    "    val_results.append((name, rmse, r2))\n",
    "\n",
    "sorted(val_results, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de761d66",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Validation RMSE is the main number we use to pick the final model.\n",
    "- R² helps sanity-check fit quality, but RMSE is easier to interpret in ₹."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b4520",
   "metadata": {},
   "source": [
    "### 10.1 Validation residuals (per model)\n",
    "\n",
    "Residual = actual - predicted.\n",
    "We want residuals centered near 0 with reasonable spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f038606",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6))\n",
    "for name, preds in val_preds.items():\n",
    "    residuals = y_val.values - preds\n",
    "    plt.hist(residuals, bins=35, alpha=0.45, label=name)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(\"Validation Residual Distributions (Actual - Predicted)\")\n",
    "plt.xlabel(\"Residual (₹)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c4f49",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Narrower residual histograms usually indicate lower error.\n",
    "- Long tails often come from premium listings and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37344209",
   "metadata": {},
   "source": [
    "## 11) Final model selection and test evaluation\n",
    "\n",
    "We pick the best model based on validation RMSE.\n",
    "Then we refit on **train + validation**.\n",
    "Finally, we evaluate once on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name, best_rmse, best_r2 = sorted(val_results, key=lambda x: x[1])[0]\n",
    "best_name, best_rmse, best_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf0536",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- We are done selecting. We do not try more models after this point.\n",
    "- The next step is final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = candidates[best_name]\n",
    "\n",
    "X_trainval_sel = X_trainval[num_features + cat_features].copy()\n",
    "\n",
    "final_pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", best_model)])\n",
    "final_pipe.fit(X_trainval_sel, y_trainval)\n",
    "\n",
    "test_preds = final_pipe.predict(X_test_sel)\n",
    "\n",
    "test_rmse = float(np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "test_r2 = float(r2_score(y_test, test_preds))\n",
    "\n",
    "test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27dced",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- This test RMSE is the closest estimate of real-world performance.\n",
    "- Do not tune hyperparameters using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db34afc",
   "metadata": {},
   "source": [
    "## 12) Error analysis on the test set\n",
    "\n",
    "We inspect:\n",
    "- residual distribution\n",
    "- biggest mistakes (largest absolute error)\n",
    "\n",
    "This helps identify where the model fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca367ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_residuals = y_test.values - test_preds\n",
    "\n",
    "plt.figure(figsize=(10.5, 5.5))\n",
    "plt.hist(test_residuals, bins=40, color=\"#B279A2\", edgecolor=\"white\", alpha=0.9)\n",
    "plt.gca().xaxis.set_major_formatter(inr_formatter)\n",
    "plt.title(f\"Test Residual Distribution (Actual - Predicted) — {best_name}\")\n",
    "plt.xlabel(\"Residual (₹)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis=\"y\", alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f65aff",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- If residuals are shifted left or right, the model is biased.\n",
    "- A wide spread means the model is not precise.\n",
    "- Outliers show up as long tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a187f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = X_test_sel.copy()\n",
    "errors[\"actual_rent\"] = y_test.values\n",
    "errors[\"predicted_rent\"] = test_preds\n",
    "errors[\"abs_error\"] = np.abs(errors[\"actual_rent\"] - errors[\"predicted_rent\"])\n",
    "\n",
    "errors.sort_values(\"abs_error\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f24ddc",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- This table is actionable.\n",
    "- It tells you which cases need better features or different modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af055521",
   "metadata": {},
   "source": [
    "### 12.1 Error by city (quick check)\n",
    "\n",
    "City can shift the rent baseline.\n",
    "We check average absolute error by city on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbecb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_err = errors.groupby(\"city\")[\"abs_error\"].mean().sort_values(ascending=False)\n",
    "print(city_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d471fc",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- If one city has much higher error, you may need more data or better features for that city.\n",
    "- This is a common production issue in geo-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103b9f3",
   "metadata": {},
   "source": [
    "## 13) Recap and next steps\n",
    "\n",
    "You built a realistic ML workflow:\n",
    "- EDA with readable plots\n",
    "- train / validation / test split\n",
    "- preprocessing pipeline (missing values + one-hot)\n",
    "- model comparison using cross-validation\n",
    "- model selection using validation\n",
    "- final evaluation on the test set\n",
    "- error analysis\n",
    "\n",
    "**Next steps**\n",
    "- Try stronger models (Random Forest, Gradient Boosting)\n",
    "- Engineer features (log(rent), rent per sqft)\n",
    "- Add locality with high-cardinality strategies\n",
    "- Add hyperparameter tuning after you lock the baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
